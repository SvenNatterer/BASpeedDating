{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19091af7",
   "metadata": {},
   "source": [
    "## Fitting Test XGB RF LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f8b2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Anzeigeoptionen anpassen\n",
    "pd.set_option('display.max_rows', None)    # zeigt alle Zeilen\n",
    "pd.set_option('display.max_columns', None) # zeigt alle Spalten\n",
    "pd.set_option('display.width', None)       # keine Begrenzung der Zeilenbreite\n",
    "pd.set_option('display.max_colwidth', None)  # keine Begrenzung der Spaltenbreite\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb16a9a",
   "metadata": {},
   "source": [
    "- pf_o: Preference of Partner \n",
    "- attr1_1: Preference Subject\n",
    "- \n",
    "- attr_o: Rating of Partner \n",
    "- attr: Rating Partner\n",
    "- \n",
    "- attr2_1: Perceived Preference Partner \n",
    "- attr3_1: Perceived Ratings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "92578814",
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import TargetEncoder \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# importiere df_preprocessed.csv\n",
    "df_extended = pd.read_csv('data/df_preprocessed.csv')\n",
    "df_pre = df_extended.copy()\n",
    "\n",
    "# Target Encoding für kategorische Spalten\n",
    "categorical_cols = df_pre.select_dtypes(include=['object']).columns.tolist()\n",
    "target_encoder = TargetEncoder(cols=categorical_cols, handle_unknown='value', handle_missing='value')\n",
    "df_pre[categorical_cols] = target_encoder.fit_transform(df_pre[categorical_cols], df_pre['match'])   \n",
    "# Median Imputation für numerische Spalten\n",
    "numerical_cols = df_pre.select_dtypes(include=[np.number]).columns.tolist()\n",
    "df_pre[numerical_cols] = df_pre[numerical_cols].fillna(df_pre[numerical_cols].median())\n",
    "\n",
    "#Scale\n",
    "X_scaled_arr = StandardScaler().fit_transform(df_pre)\n",
    "X_scaled = pd.DataFrame(X_scaled_arr, columns=df_pre.columns, index=df_pre.index)\n",
    "\n",
    "# Train Test Split and Scaling\n",
    "X_pca = X_scaled.drop([\"match\"], axis=1)\n",
    "y_pca = X_scaled[\"match\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf89bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gruppen IDs: [1 1 1 1 1 1 2 1 1 1 3 3 3 3 3 3 4 4 4 4 4 4 1 1 1 1 1 3 3 1 1 1 1 1 1 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 3 3 3 3 3 3 5 5 5 5 5 5 5 5 5 5 5 4 4 4 4\n",
      " 4 4 1]\n"
     ]
    }
   ],
   "source": [
    "groups_map = {\n",
    "    \"gerneral\": [\"gender\", \"condtn\", \"wave\", \"round\", \"position\", \"order\", \"samerace\", \"age_o\", \"race_o\", \"age\", \"field\", \"field_cd\",\"race\",\"from\", \"goal\", \"date\", \"go_out\",\n",
    "                 \"career\", \"career_c\",\"met\", \"met_o\", \"exphappy\"],\n",
    "    \"interests\": [\"int_corr\", \"sports\", \"tvsports\", \"exercise\", \"dining\", \"museums\", \"art\", \"hiking\", \"gaming\", \"clubbing\", \"reading\", \"tv\", \"theater\",\n",
    "                  \"movies\", \"concerts\", \"music\", \"shopping\", \"yoga\"],\n",
    "    \"preferences\": [\"pf_o_att\", \"pf_o_sin\", \"pf_o_int\", \"pf_o_fun\", \"pf_o_amb\", \"pf_o_sha\",\"imprace\", \"imprelig\", \"attr1_1\", \"sinc1_1\", \"intel1_1\", \"fun1_1\", \"amb1_1\", \"shar1_1\"],\n",
    "    \"ratings\": [\"attr_o\", \"sinc_o\", \"intel_o\", \"fun_o\", \"amb_o\", \"shar_o\",\"like_o\", \"prob_o\",\"attr\", \"sinc\", \"intel\", \"fun\", \"like\", \"prob\"],\n",
    "    \"selfassesment\": [\"attr2_1\", \"sinc2_1\", \"intel2_1\", \"fun2_1\", \"amb2_1\", \"shar2_1\", \"attr3_1\", \"sinc3_1\", \"intel3_1\", \"fun3_1\", \"amb3_1\", \"shar3_1\"]\n",
    "}\n",
    "\n",
    "group_ids = []\n",
    "for col in X_pca.columns:\n",
    "    gid = next(\n",
    "        (i+1 for i, cols in enumerate(groups_map.values()) if col in cols),\n",
    "        -1\n",
    "    )\n",
    "    group_ids.append(gid)\n",
    "group_ids = np.array(group_ids)\n",
    "print(\"Gruppen IDs:\", group_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bad5468c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indizes ausgewählter Features: [16 17 18 19 20 21 70 71 72 73 74 75]\n"
     ]
    }
   ],
   "source": [
    "from group_lasso import GroupLasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "gl = GroupLasso(\n",
    "    groups=group_ids,\n",
    "    group_reg=0.1,   # λ₂\n",
    "    l1_reg=0.001,      # λ₁\n",
    "    n_iter=5000,\n",
    "    tol=1e-03,\n",
    "    supress_warning=True# ← altes Scaling durch Eigenwert wieder einschalten\n",
    ")\n",
    "gl.fit(X_pca, y_pca)\n",
    "β = gl.coef_\n",
    "\n",
    "\n",
    "\n",
    "#print(\"Koeffizienten:\", gl.coef_)\n",
    "\n",
    "# Maske der ausgewählten Features\n",
    "mask = gl.sparsity_mask_\n",
    "#print(\"Ausgewählte Features (Maske):\", mask)\n",
    "\n",
    "# Indizes der ausgewählten Features\n",
    "selected_idx = np.where(mask)[0]\n",
    "print(\"Indizes ausgewählter Features:\", selected_idx)\n",
    "\n",
    "# Falls X ein DataFrame ist, kannst du auch direkt die Spaltennamen holen:\n",
    "# selected_cols = X.columns[selected_idx]\n",
    "# print(\"Ausgewählte Spalten:\", selected_cols)\n",
    "\n",
    "# IDs der ausgewählten Gruppen\n",
    "#print(\"Ausgewählte Gruppen:\", gl.chosen_groups_)\n",
    "\n",
    "X = X_pca.iloc[:, selected_idx]\n",
    "y = df_extended[\"match\"]\n",
    "# mache mir einen train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0ef405cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attr_o</th>\n",
       "      <th>sinc_o</th>\n",
       "      <th>intel_o</th>\n",
       "      <th>fun_o</th>\n",
       "      <th>like_o</th>\n",
       "      <th>prob_o</th>\n",
       "      <th>attr</th>\n",
       "      <th>sinc</th>\n",
       "      <th>intel</th>\n",
       "      <th>fun</th>\n",
       "      <th>like</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5677</th>\n",
       "      <td>0.422940</td>\n",
       "      <td>1.654736</td>\n",
       "      <td>-0.889989</td>\n",
       "      <td>-0.222596</td>\n",
       "      <td>-0.623334</td>\n",
       "      <td>0.382829</td>\n",
       "      <td>-2.172415</td>\n",
       "      <td>-2.436115</td>\n",
       "      <td>-0.889343</td>\n",
       "      <td>-1.265928</td>\n",
       "      <td>-1.173853</td>\n",
       "      <td>-0.574056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>0.942262</td>\n",
       "      <td>-0.098938</td>\n",
       "      <td>0.422860</td>\n",
       "      <td>0.821586</td>\n",
       "      <td>1.030825</td>\n",
       "      <td>-0.095914</td>\n",
       "      <td>-0.096238</td>\n",
       "      <td>0.485326</td>\n",
       "      <td>1.078848</td>\n",
       "      <td>-0.744033</td>\n",
       "      <td>-0.622812</td>\n",
       "      <td>0.861241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4366</th>\n",
       "      <td>-1.135028</td>\n",
       "      <td>-0.098938</td>\n",
       "      <td>-0.233564</td>\n",
       "      <td>0.299495</td>\n",
       "      <td>0.479439</td>\n",
       "      <td>0.861573</td>\n",
       "      <td>-0.615282</td>\n",
       "      <td>-1.267538</td>\n",
       "      <td>-2.201469</td>\n",
       "      <td>-1.787822</td>\n",
       "      <td>-2.275935</td>\n",
       "      <td>-2.009352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5688</th>\n",
       "      <td>-0.615705</td>\n",
       "      <td>0.485620</td>\n",
       "      <td>1.079285</td>\n",
       "      <td>0.821586</td>\n",
       "      <td>-0.071947</td>\n",
       "      <td>-2.010888</td>\n",
       "      <td>-0.096238</td>\n",
       "      <td>-0.098962</td>\n",
       "      <td>-0.233279</td>\n",
       "      <td>0.299756</td>\n",
       "      <td>-0.071771</td>\n",
       "      <td>-0.095624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>-1.654350</td>\n",
       "      <td>0.485620</td>\n",
       "      <td>-1.546414</td>\n",
       "      <td>-0.744687</td>\n",
       "      <td>-1.174720</td>\n",
       "      <td>-1.532145</td>\n",
       "      <td>0.422806</td>\n",
       "      <td>-0.098962</td>\n",
       "      <td>-0.233279</td>\n",
       "      <td>-0.744033</td>\n",
       "      <td>-0.071771</td>\n",
       "      <td>-2.009352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        attr_o    sinc_o   intel_o     fun_o    like_o    prob_o      attr  \\\n",
       "5677  0.422940  1.654736 -0.889989 -0.222596 -0.623334  0.382829 -2.172415   \n",
       "664   0.942262 -0.098938  0.422860  0.821586  1.030825 -0.095914 -0.096238   \n",
       "4366 -1.135028 -0.098938 -0.233564  0.299495  0.479439  0.861573 -0.615282   \n",
       "5688 -0.615705  0.485620  1.079285  0.821586 -0.071947 -2.010888 -0.096238   \n",
       "208  -1.654350  0.485620 -1.546414 -0.744687 -1.174720 -1.532145  0.422806   \n",
       "\n",
       "          sinc     intel       fun      like      prob  \n",
       "5677 -2.436115 -0.889343 -1.265928 -1.173853 -0.574056  \n",
       "664   0.485326  1.078848 -0.744033 -0.622812  0.861241  \n",
       "4366 -1.267538 -2.201469 -1.787822 -2.275935 -2.009352  \n",
       "5688 -0.098962 -0.233279  0.299756 -0.071771 -0.095624  \n",
       "208  -0.098962 -0.233279 -0.744033 -0.071771 -2.009352  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4275b8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LogisticRegression ===\n",
      "Accuracy   : 0.847\n",
      "F1-Score   : 0.388\n",
      "ROC AUC    : 0.846\n",
      "\n",
      "=== RandomForest ===\n",
      "Accuracy   : 0.856\n",
      "F1-Score   : 0.447\n",
      "ROC AUC    : 0.836\n",
      "\n",
      "=== XGBoost ===\n",
      "Accuracy   : 0.844\n",
      "F1-Score   : 0.436\n",
      "ROC AUC    : 0.831\n",
      "\n",
      "=== KNN ===\n",
      "Accuracy   : 0.839\n",
      "F1-Score   : 0.431\n",
      "ROC AUC    : 0.767\n",
      "\n",
      "=== SVM ===\n",
      "Accuracy   : 0.853\n",
      "F1-Score   : 0.375\n",
      "ROC AUC    : 0.773\n"
     ]
    }
   ],
   "source": [
    "from category_encoders import TargetEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline       import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from category_encoders import CountEncoder\n",
    "from sklearn.svm import SVC\n",
    "from xgboost                import XGBClassifier\n",
    "from sklearn.linear_model   import LogisticRegression\n",
    "from sklearn.ensemble       import RandomForestClassifier\n",
    "import joblib\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, classification_report\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "#Funktion zum Erzeugen des passenden Preprocessors\n",
    "def make_preprocessor(model_name, numeric_features, categorical_features):\n",
    "    cat_encoder = encoding_strategies[model_name]\n",
    "    categorical_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", cat_encoder)\n",
    "    ])\n",
    "    return ColumnTransformer([\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_pipeline, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Numerische und kategoriale Features ermitteln (unverändert)\n",
    "numeric_features = X.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "# Transformer für numerische und kategoriale Daten definieren (unverändert)\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),      # fehlende Werte durch Median ersetzen\n",
    "    (\"scaler\", StandardScaler())                        # Standardisierung\n",
    "])\n",
    "\n",
    "# 2) Encoding-Strategien je Modell festlegen\n",
    "encoding_strategies = {\n",
    "    \"LogisticRegression\":TargetEncoder(handle_unknown=\"ignore\"),\n",
    "    \"RandomForest\":      OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1),\n",
    "    \"XGBoost\":           OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1),\n",
    "    \"KNN\":               CountEncoder(handle_unknown=\"ignore\"),\n",
    "    \"SVM\":               TargetEncoder(handle_unknown=\"ignore\")\n",
    "}\n",
    "\n",
    "models = [\n",
    "    (\"LogisticRegression\", LogisticRegression(random_state=42)),\n",
    "    (\"RandomForest\",       RandomForestClassifier(max_features= 3,random_state=42)),\n",
    "    (\"XGBoost\",            XGBClassifier(random_state=42)),\n",
    "    (\"KNN\",                KNeighborsClassifier()),\n",
    "    (\"SVM\",                SVC(probability=True, random_state=42))\n",
    "]\n",
    "\n",
    "scoring = {\n",
    "    \"Accuracy\":       \"accuracy\",\n",
    "    \"ROC_AUC\":        \"roc_auc_ovo_weighted\",\n",
    "    \"F1\":             \"f1_macro\"\n",
    "}\n",
    "\n",
    "for name, clf in models:\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocessor\", make_preprocessor(name, numeric_features, categorical_features)),\n",
    "        (\"classifier\",   clf)\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    # 2) Vorhersagen\n",
    "    y_pred  = pipe.predict(X_test)\n",
    "    y_proba = pipe.predict_proba(X_test)[:, 1] \n",
    "    \n",
    "    # 3) Metriken berechnen\n",
    "    acc   = accuracy_score(y_test, y_pred)\n",
    "    f1    = f1_score(y_test, y_pred)\n",
    "    roc   = roc_auc_score(y_test, y_proba)      # für Binary nur y_proba[:,1]\n",
    "    \n",
    "    # 4) Ausgabe\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"Accuracy   : {acc:.3f}\")\n",
    "    print(f\"F1-Score   : {f1:.3f}\")\n",
    "    print(f\"ROC AUC    : {roc:.3f}\")\n",
    "\n",
    "    \n",
    "    # 5) Modell speichern\n",
    "    filename = f\"model_{name}.pkl\"\n",
    "    joblib.dump(pipe, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21f20f2",
   "metadata": {},
   "source": [
    "CV für Hyperparameter und robuste unbiased Schätzung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc1c94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    cv_results = cross_validate(\n",
    "        pipe,\n",
    "        X_train, y_train,\n",
    "        cv=5,\n",
    "        scoring=scoring,\n",
    "        return_train_score=False\n",
    "    )\n",
    "    mean_scores = {}\n",
    "    for metric in scoring:\n",
    "        m = cv_results[f\"test_{metric}\"]\n",
    "        mean_scores[metric] = m.mean()\n",
    "        print(f\"  {metric:15s}: {m.mean():.3f} ± {m.std():.3f}\")\n",
    "\n",
    "    overall_avg = np.mean(list(mean_scores.values()))\n",
    "    print(f\"  {'Overall average':15s}: {overall_avg:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724c3dc3",
   "metadata": {},
   "source": [
    "## RF Model/Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ef6b8f",
   "metadata": {},
   "source": [
    "Sparse Group Lasso"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
